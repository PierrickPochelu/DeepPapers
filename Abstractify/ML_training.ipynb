{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260e5bb2-7c6b-45e7-9270-4d3ae51915e8",
   "metadata": {},
   "source": [
    "# Arxiv analysis for topic detection\n",
    "\n",
    "The goal of the document is to analyze the database https://huggingface.co/datasets/real-jiakai/arxiver-with-category\n",
    "\n",
    "The document is structured as following:\n",
    "\n",
    "0) Load Prerequisites\n",
    "1) Gaining Insights on the Database\n",
    "2) Exploring the Relevant Pre-processing for Feeding a Machine Learning Model\n",
    "3) Exploring a Few Hyperparameters\n",
    "4) Training a Deep Learning model with Transformers/HuggingFace/PyTorch\n",
    "5) Prompt engineering of OpenAI API\n",
    "\n",
    "==> Files (stored in $MODEL_PATH) and inference codes of this document are integrated in the gradio code (ui.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b12f968-7bc3-4a3d-90a1-37e0da77713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change global variables to your environment\n",
    "MODEL_PATH = \"/home/pierrick/project/ARXIV/models/\"\n",
    "OPENAI_API_KEY = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e72842-4976-4b58-9e86-e1285ef6772b",
   "metadata": {},
   "source": [
    "# Load Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aeb891-af0e-4c82-9fa1-a150d2ff8553",
   "metadata": {},
   "source": [
    "## Some imports for loading dataset / english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9be6900-55a0-4dd5-a356-9600899f6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c5998-3ae1-419b-a637-5d7be029b716",
   "metadata": {},
   "source": [
    "## Load the dataset in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fee25dc-1d8a-4a32-bff9-9e8198ef6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"real-jiakai/arxiver-with-category\")\n",
    "\n",
    "# Convert dataset to a Pandas DataFrame\n",
    "df = pd.DataFrame(dataset['train'])  # Using the 'train' split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f85b3d-6bcb-4be4-b4a0-3253b69505e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'abstract', 'authors', 'published_date', 'link', 'markdown', 'primary_category', 'categories'],\n",
       "        num_rows: 63357\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02af5cc1-3c9e-4967-89f6-efe04db42b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63357"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cf3e6-4fdb-4cbc-93da-2b2c144398a3",
   "metadata": {},
   "source": [
    "## Load english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782b6928-adfd-4e95-87ac-90fe8e965754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words: 235892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /home/pierrick/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download word list if not available\n",
    "nltk.download(\"words\")\n",
    "\n",
    "# Load a set of valid English words for quick lookup\n",
    "english_words = set(words.words())\n",
    "print(\"# words:\", len(english_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae469c9-e192-404c-9934-3031c7cba3e5",
   "metadata": {},
   "source": [
    "## My utilities for processing english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420d1d01-3dd5-4d89-8555-2cc853b95132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text from document:    Hello 4ll ! I am a self-instruct robot. ##### 404 \n",
      "Ratio of clean text: 0.6363636363636364\n",
      "Clean text `clean_english`: hello i am a self instruct robot\n"
     ]
    }
   ],
   "source": [
    "def clean_english(text): # <-------------- interpretable but create an accuracy loss. So i don t use it anymore (from 50% to 43% on titles)\n",
    "    text=text.replace(\"-\", \" \") #  usefull in many situations ex: \"zero-shot\", \"discrete-event\"\n",
    "    \n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize: split by whitespace\n",
    "    tokens = cleaned_text.lower().split()\n",
    "    \n",
    "    # Filter: Keep only words in the English dictionary\n",
    "    english_text = [word for word in tokens if word in english_words]\n",
    "    return \" \".join(english_text)\n",
    "\n",
    "def ratio_english_words(text):\n",
    "    text=text.replace(\"-\", \" \")\n",
    "    num_start=len(text.split())\n",
    "    num_after=len(clean_english(text).split())\n",
    "\n",
    "    if num_start==0:\n",
    "        return 1.\n",
    "    ratio = num_after/float(num_start)\n",
    "    return min(ratio, 1.)\n",
    "\n",
    "\n",
    "# Testing my functions\n",
    "raw_text = \"   Hello 4ll ! I am a self-instruct robot. ##### 404 \"\n",
    "print(\"Raw text from document:\", raw_text)\n",
    "print(\"Ratio of clean text:\", ratio_english_words(raw_text))\n",
    "print(\"Clean text `clean_english`:\", clean_english(raw_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a96041-25ad-4e1c-a965-7cef8c819e72",
   "metadata": {},
   "source": [
    "# Data quality check before training ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8406c6-1b6c-4eb0-a7f7-becdd4315def",
   "metadata": {},
   "source": [
    "## Simple insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d54af1de-d0fa-4adf-a9ca-da8520f3c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m \u001b[1m *** PANDAS INFO *** \u001b[0m \u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63357 entries, 0 to 63356\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   id                63357 non-null  object        \n",
      " 1   title             63357 non-null  object        \n",
      " 2   abstract          63357 non-null  object        \n",
      " 3   authors           63357 non-null  object        \n",
      " 4   published_date    63357 non-null  datetime64[ns]\n",
      " 5   link              63357 non-null  object        \n",
      " 6   markdown          63357 non-null  object        \n",
      " 7   primary_category  63357 non-null  object        \n",
      " 8   categories        63357 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 4.4+ MB\n",
      "None\n",
      "\u001b[31m \u001b[1m *** FIRST 5 ROWS *** \u001b[0m \u001b[0m\n",
      "           id                                              title  \\\n",
      "0  2302.12141  Characterizing the nucleus of comet 162P/Sidin...   \n",
      "1  2301.08449  Revealing the supercritical dynamics of dusty ...   \n",
      "2  2302.11448  On properties described by terms in commutator...   \n",
      "3  2302.09207    RETVec: Resilient and Efficient Text Vectorizer   \n",
      "4  2310.06325  Long-time behavior for the Kirchhoff diffusion...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Comet 162P/Siding Spring is a large Jupiter-fa...   \n",
      "1  Dusty plasmas represent a powerful playground ...   \n",
      "2  We investigate properties of varieties of alge...   \n",
      "3  This paper describes RETVec, an efficient, res...   \n",
      "4  We consider a Kirchhoff-type diffusion problem...   \n",
      "\n",
      "                                             authors      published_date  \\\n",
      "0  Abbie Donaldson, Rosita Kokotanekova, Agata Ro... 2023-02-23 16:27:58   \n",
      "1  Dong Huang, Matteo Baggioli, Shaoyu Lu, Zhuang... 2023-01-20 07:04:42   \n",
      "2                                 Stefano Fioravanti 2023-02-22 15:34:23   \n",
      "3  Elie Bursztein, Marina Zhang, Owen Vallis, Xin... 2023-02-18 02:06:52   \n",
      "4  Jiabin Zuo, Juliana Honda Lopes, Vicentiu D. R... 2023-10-10 05:45:42   \n",
      "\n",
      "                                link  \\\n",
      "0  http://arxiv.org/abs/2302.12141v1   \n",
      "1  http://arxiv.org/abs/2301.08449v1   \n",
      "2  http://arxiv.org/abs/2302.11448v2   \n",
      "3  http://arxiv.org/abs/2302.09207v3   \n",
      "4  http://arxiv.org/abs/2310.06325v1   \n",
      "\n",
      "                                            markdown  primary_category  \\\n",
      "0  # Characterizing the nucleus of comet 162P/Sid...       astro-ph.EP   \n",
      "1  Revealing the supercritical dynamics of dusty ...  physics.plasm-ph   \n",
      "2  # On properties described by terms in commutat...           math.RA   \n",
      "3  # RetVec: Resilient and Efficient Text Vectori...             cs.CL   \n",
      "4  # Long-time behavior for the Kirchhoff diffusi...           math.AP   \n",
      "\n",
      "                                          categories  \n",
      "0                                      [astro-ph.EP]  \n",
      "1  [physics.plasm-ph, cond-mat.soft, cond-mat.sta...  \n",
      "2                   [math.RA, \"03C05, 08B05, 08B10\"]  \n",
      "3                                     [cs.CL, cs.AI]  \n",
      "4                   [math.AP, \"35R11, 35J20, 35J60\"]  \n",
      "\u001b[31m \u001b[1m *** MISSING VALUE COUNT *** \u001b[0m \u001b[0m\n",
      "Missing Values: id                  0\n",
      "title               0\n",
      "abstract            0\n",
      "authors             0\n",
      "published_date      0\n",
      "link                0\n",
      "markdown            0\n",
      "primary_category    0\n",
      "categories          0\n",
      "dtype: int64\n",
      "\u001b[31m \u001b[1m *** ENGLISH WORDS RATIO *** \u001b[0m \u001b[0m\n",
      "Column 'title' :\n",
      "count    63357.000000\n",
      "mean         0.757929\n",
      "std          0.147121\n",
      "min          0.000000\n",
      "25%          0.666667\n",
      "50%          0.777778\n",
      "75%          0.857143\n",
      "max          1.000000\n",
      "Name: title, dtype: float64\n",
      "Column 'abstract' :\n",
      "count    63357.000000\n",
      "mean         0.804395\n",
      "std          0.053585\n",
      "min          0.336842\n",
      "25%          0.771812\n",
      "50%          0.807692\n",
      "75%          0.841060\n",
      "max          1.000000\n",
      "Name: abstract, dtype: float64\n",
      "Column 'markdown' :\n",
      "count    63357.000000\n",
      "mean         0.785309\n",
      "std          0.056908\n",
      "min          0.071429\n",
      "25%          0.753333\n",
      "50%          0.790210\n",
      "75%          0.823529\n",
      "max          0.990196\n",
      "Name: markdown, dtype: float64\n",
      "\u001b[31m \u001b[1m *** INTERESTING FIELD : CHARA. LENGTH *** \u001b[0m \u001b[0m\n",
      "title : \n",
      "count    63357.000000\n",
      "mean        76.860836\n",
      "std         25.775971\n",
      "min          7.000000\n",
      "25%         59.000000\n",
      "50%         76.000000\n",
      "75%         93.000000\n",
      "max        231.000000\n",
      "Name: title, dtype: float64\n",
      "abstract : \n",
      "count    63357.000000\n",
      "mean      1110.253942\n",
      "std        393.919390\n",
      "min          3.000000\n",
      "25%        837.000000\n",
      "50%       1109.000000\n",
      "75%       1390.000000\n",
      "max       2427.000000\n",
      "Name: abstract, dtype: float64\n",
      "markdown : \n",
      "count    6.335700e+04\n",
      "mean     4.712734e+04\n",
      "std      3.807042e+04\n",
      "min      1.330000e+02\n",
      "25%      2.654400e+04\n",
      "50%      3.839800e+04\n",
      "75%      5.665900e+04\n",
      "max      1.916461e+06\n",
      "Name: markdown, dtype: float64\n",
      "\u001b[31m \u001b[1m *** RIMARY CATEG. BALANCE *** \u001b[0m \u001b[0m\n",
      "Counter({'cs.CV': 5448, 'cs.LG': 5351, 'cs.CL': 4321, 'quant-ph': 2930, 'hep-ph': 1642, 'cs.RO': 1632, 'cs.AI': 1196, 'gr-qc': 1187, 'astro-ph.GA': 1138, 'cs.CR': 1122, 'cond-mat.mtrl-sci': 1041, 'math.CO': 1031, 'astro-ph.HE': 961, 'cond-mat.mes-hall': 960, 'hep-th': 918, 'math.AP': 914, 'eess.SY': 892, 'eess.IV': 864, 'astro-ph.SR': 794, 'physics.optics': 774, 'math.OC': 749, 'cs.SE': 742, 'cond-mat.str-el': 729, 'math.NA': 728, 'cs.HC': 708, 'math.NT': 702, 'physics.flu-dyn': 692, 'eess.SP': 689, 'stat.ME': 668, 'math.PR': 604, 'astro-ph.EP': 592, 'astro-ph.CO': 591, 'math.AG': 572, 'cond-mat.stat-mech': 567, 'cs.IR': 548, 'stat.ML': 542, 'cs.IT': 538, 'cond-mat.soft': 533, 'math.DG': 488, 'cs.SD': 471, 'cs.DC': 445, 'math.DS': 434, 'cs.NI': 433, 'cs.DS': 424, 'cs.CY': 413, 'nucl-th': 412, 'cs.LO': 397, 'eess.AS': 394, 'cond-mat.supr-con': 381, 'astro-ph.IM': 377, 'math-ph': 365, 'math.FA': 355, 'cs.SI': 318, 'math.GR': 300, 'physics.soc-ph': 283, 'physics.chem-ph': 276, 'physics.plasm-ph': 269, 'cond-mat.quant-gas': 263, 'cs.GT': 244, 'math.GT': 240, 'physics.app-ph': 239, 'math.RT': 238, 'cs.NE': 238, 'math.CA': 236, 'physics.atom-ph': 233, 'math.ST': 232, 'stat.AP': 231, 'physics.ins-det': 227, 'math.RA': 213, 'math.LO': 213, 'cs.DB': 205, 'hep-ex': 203, 'cs.AR': 193, 'math.AT': 192, 'cs.PL': 187, 'math.CV': 184, 'q-bio.NC': 183, 'math.AC': 171, 'cond-mat.dis-nn': 158, 'q-bio.PE': 150, 'physics.acc-ph': 145, 'physics.comp-ph': 140, 'hep-lat': 137, 'physics.med-ph': 133, 'econ.GN': 131, 'q-bio.QM': 129, 'physics.ao-ph': 129, 'cs.FL': 128, 'math.CT': 127, 'cs.CE': 123, 'cs.MA': 123, 'cs.GR': 120, 'physics.geo-ph': 114, 'math.OA': 110, 'cs.DL': 109, 'math.GM': 109, 'cs.CC': 107, 'physics.bio-ph': 106, 'nucl-ex': 100, 'math.MG': 99, 'math.QA': 95, 'cs.DM': 88, 'stat.CO': 88, 'cs.CG': 88, 'econ.EM': 86, 'physics.ed-ph': 78, 'math.GN': 78, 'q-bio.BM': 77, 'cs.MM': 76, 'physics.gen-ph': 72, 'nlin.SI': 71, 'econ.TH': 71, 'nlin.AO': 70, 'cs.ET': 67, 'nlin.PS': 67, 'physics.class-ph': 65, 'math.HO': 64, 'physics.hist-ph': 57, 'math.SP': 57, 'q-fin.ST': 56, 'physics.space-ph': 55, 'physics.data-an': 51, 'math.SG': 51, 'q-bio.MN': 47, 'nlin.CD': 46, 'q-bio.GN': 41, 'q-fin.MF': 31, 'cs.SC': 31, 'cs.MS': 29, 'q-fin.PM': 29, 'q-fin.TR': 28, 'cond-mat.other': 28, 'q-fin.CP': 28, 'math.KT': 25, 'cs.PF': 25, 'q-fin.RM': 23, 'cs.OH': 23, 'q-fin.GN': 21, 'cs.OS': 20, 'q-bio.CB': 18, 'stat.OT': 17, 'q-bio.TO': 16, 'physics.pop-ph': 16, 'q-bio.OT': 15, 'q-fin.PR': 15, 'physics.atm-clus': 9, 'nlin.CG': 8, 'cs.GL': 2, 'q-bio.SC': 1})\n",
      "#Primary category:  149\n",
      "\u001b[31m \u001b[1m *** SUPER PRIMARY CATEG. BALANCE *** \u001b[0m \u001b[0m\n",
      "Counter({'cs': 26733, 'math': 9611, 'cond-mat': 4660, 'astro-ph': 4453, 'physics': 4163, 'quant-ph': 2930, 'eess': 2839, 'hep-ph': 1642, 'stat': 1546, 'gr-qc': 1187, 'hep-th': 918, 'q-bio': 677, 'nucl-th': 412, 'math-ph': 365, 'econ': 288, 'nlin': 262, 'q-fin': 231, 'hep-ex': 203, 'hep-lat': 137, 'nucl-ex': 100})\n",
      "#Super category:  20\n"
     ]
    }
   ],
   "source": [
    "def title(txt):\n",
    "    print(f\"\\033[31m \\033[1m *** {txt.upper()} *** \\033[0m \\033[0m\")\n",
    "\n",
    "title(\"PANDAS INFO\")\n",
    "print(df.info())\n",
    "\n",
    "title(\"FIRST 5 rows\")\n",
    "print(df.head(5))\n",
    "\n",
    "title(\"MISSING VALUE COUNT\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\", missing_values)\n",
    "\n",
    "\n",
    "title(\"ENGLISH WORDS RATIO\")\n",
    "text_columns = [\"title\", \"abstract\", \"markdown\"]\n",
    "for col in text_columns:\n",
    "    stats = df[col].apply(lambda v: ratio_english_words(v[:1000])).describe()\n",
    "    print(f\"Column '{col}' :\")\n",
    "    print(stats)\n",
    "\n",
    "\n",
    "title(\"INTERESTING FIELD : CHARA. LENGTH\")\n",
    "text_columns = [\"title\", \"abstract\", \"markdown\"]\n",
    "for col in text_columns:\n",
    "    stats = df[col].str.len().describe()\n",
    "    print(col, \": \")\n",
    "    print(stats)\n",
    "\n",
    "title(\"RIMARY CATEG. BALANCE\")\n",
    "primary_freq=Counter(df[\"primary_category\"])\n",
    "print(primary_freq)\n",
    "print(\"#Primary category: \", len(primary_freq))\n",
    "\n",
    "title(\"SUPER PRIMARY CATEG. BALANCE\")\n",
    "df[\"primary_category_super\"]=df[\"primary_category\"].apply(lambda v: v.split(\".\")[0])\n",
    "super_primary_freq=Counter(df[\"primary_category_super\"])\n",
    "print(super_primary_freq)\n",
    "print(\"#Super category: \", len(super_primary_freq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba00354-ebf7-4f6e-8845-4cda22b69ae4",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a9c0ae-7864-4031-bf0b-3b94112b15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['markdown'] = df['markdown'].str[:10000] # Free memory, keep the beginning (should contain the introduction)\n",
    "df[\"title_plus_abstract\"] = df[\"title\"] + \" \" + df[\"abstract\"]\n",
    "df[\"title_plus_abstract_plus_intro\"] = df[\"title\"] + \" \" + df[\"abstract\"] + \" \" + df[\"markdown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c93d2-704d-4025-9a36-08715f21596d",
   "metadata": {},
   "source": [
    "# Class Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a381c-6e11-4035-92c1-87ac98a3ea8e",
   "metadata": {},
   "source": [
    "Many questions occur:\n",
    "* How many data samples per class for balancing between granularity ?\n",
    "* What is the best field to predict the class (title, abstract, markdown) ?\n",
    "* Is there any low hanging fruit ? (Example: open source model doing it already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5547666-abbe-43d9-bcde-7e07700a921b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m \u001b[1m *** BALANCED CATEG. FREQUENCY : FROM SMALL NODE TO PARENT NODE *** \u001b[0m \u001b[0m\n",
      "Counter({'cs.CV': 5448, 'cs.LG': 5351, 'cs.CL': 4321, 'quant-ph': 2930, 'hep-ph': 1642, 'cs.RO': 1632, 'cs.AI': 1196, 'gr-qc': 1187, 'astro-ph.GA': 1138, 'cs.CR': 1122, 'cond-mat.mtrl-sci': 1041, 'math.CO': 1031, 'astro-ph.HE': 961, 'cond-mat.mes-hall': 960, 'hep-th': 918, 'math.AP': 914, 'eess.SY': 892, 'eess.IV': 864, 'astro-ph.SR': 794, 'physics.optics': 774, 'math.OC': 749, 'cs.SE': 742, 'cond-mat.str-el': 729, 'math.NA': 728, 'cs.HC': 708, 'math.NT': 702, 'physics.flu-dyn': 692, 'eess.SP': 689, 'stat.ME': 668, 'math.PR': 604, 'astro-ph.EP': 592, 'astro-ph.CO': 591, 'math.AG': 572, 'cond-mat.stat-mech': 567, 'cs.IR': 548, 'stat.ML': 542, 'cs.IT': 538, 'cond-mat.soft': 533, 'math.DG': 488, 'cs.SD': 471, 'math': 469, 'cs': 449, 'cs.DC': 445, 'math.DS': 434, 'cs.NI': 433, 'cs.DS': 424, 'cs.CY': 413, 'nucl-th': 412, 'physics': 403, 'cs.LO': 397, 'eess.AS': 394, 'cond-mat.supr-con': 381, 'astro-ph.IM': 377, 'math-ph': 365, 'math.FA': 355, 'cs.SI': 318, 'math.GR': 300, 'physics.soc-ph': 283, 'physics.chem-ph': 276, 'physics.plasm-ph': 269, 'cond-mat.quant-gas': 263, 'nlin': 262, 'cs.GT': 244, 'math.GT': 240, 'physics.app-ph': 239, 'math.RT': 238, 'cs.NE': 238, 'math.CA': 236, 'physics.atom-ph': 233, 'math.ST': 232, 'q-fin': 231, 'stat.AP': 231, 'physics.ins-det': 227, 'q-bio': 215, 'math.RA': 213, 'math.LO': 213, 'cs.DB': 205, 'hep-ex': 203, 'cs.AR': 193, 'math.AT': 192, 'cs.PL': 187, 'math.CV': 184, 'q-bio.NC': 183, 'math.AC': 171, 'cond-mat.dis-nn': 158, 'econ': 157, 'q-bio.PE': 150, 'physics.acc-ph': 145, 'physics.comp-ph': 140, 'hep-lat': 137, 'physics.med-ph': 133, 'econ.GN': 131, 'q-bio.QM': 129, 'physics.ao-ph': 129, 'cs.FL': 128, 'math.CT': 127, 'cs.CE': 123, 'cs.MA': 123, 'cs.GR': 120, 'physics.geo-ph': 114, 'math.OA': 110, 'cs.DL': 109, 'math.GM': 109, 'cs.CC': 107, 'physics.bio-ph': 106, 'stat': 105, 'nucl-ex': 100, 'cond-mat': 28})\n",
      "\u001b[31m \u001b[1m *** BALANCED CATEG. FREQUENCY 2 : FROM NODE TO REJECT NODE *** \u001b[0m \u001b[0m\n",
      "Counter({'cs.CV': 5448, 'cs.LG': 5351, 'cs.CL': 4321, 'quant-ph': 2930, 'hep-ph': 1642, 'cs.RO': 1632, 'cs.AI': 1196, 'gr-qc': 1187, 'astro-ph.GA': 1138, 'cs.CR': 1122, 'cond-mat.mtrl-sci': 1041, 'math.CO': 1031, 'astro-ph.HE': 961, 'cond-mat.mes-hall': 960, 'hep-th': 918, 'math.AP': 914, 'eess.SY': 892, 'eess.IV': 864, 'astro-ph.SR': 794, 'physics.optics': 774, 'math.OC': 749, 'cs.SE': 742, 'cond-mat.str-el': 729, 'math.NA': 728, 'cs.HC': 708, 'math.NT': 702, 'physics.flu-dyn': 692, 'eess.SP': 689, 'stat.ME': 668, 'math.PR': 604, 'astro-ph.EP': 592, 'astro-ph.CO': 591, 'math.AG': 572, 'cond-mat.stat-mech': 567, 'cs.IR': 548, 'stat.ML': 542, 'cs.IT': 538, 'cond-mat.soft': 533, 'math.DG': 488, 'cs.SD': 471, 'math': 469, 'cs': 449, 'cs.DC': 445, 'math.DS': 434, 'cs.NI': 433, 'cs.DS': 424, 'cs.CY': 413, 'nucl-th': 412, 'physics': 403, 'cs.LO': 397, 'eess.AS': 394, 'cond-mat.supr-con': 381, 'astro-ph.IM': 377, 'math-ph': 365, 'math.FA': 355, 'cs.SI': 318, 'math.GR': 300, 'physics.soc-ph': 283, 'physics.chem-ph': 276, 'physics.plasm-ph': 269, 'cond-mat.quant-gas': 263, 'nlin': 262, 'cs.GT': 244, 'math.GT': 240, 'physics.app-ph': 239, 'math.RT': 238, 'cs.NE': 238, 'math.CA': 236, 'physics.atom-ph': 233, 'math.ST': 232, 'q-fin': 231, 'stat.AP': 231, 'physics.ins-det': 227, 'q-bio': 215, 'math.RA': 213, 'math.LO': 213, 'cs.DB': 205, 'hep-ex': 203, 'cs.AR': 193, 'math.AT': 192, 'cs.PL': 187, 'math.CV': 184, 'q-bio.NC': 183, 'math.AC': 171, 'cond-mat.dis-nn': 158, 'econ': 157, 'q-bio.PE': 150, 'physics.acc-ph': 145, 'physics.comp-ph': 140, 'hep-lat': 137, 'physics.med-ph': 133, 'econ.GN': 131, 'q-bio.QM': 129, 'physics.ao-ph': 129, 'cs.FL': 128, 'math.CT': 127, 'cs.CE': 123, 'cs.MA': 123, 'cs.GR': 120, 'physics.geo-ph': 114, 'math.OA': 110, 'cs.DL': 109, 'math.GM': 109, 'cs.CC': 107, 'physics.bio-ph': 106, 'stat': 105, 'nucl-ex': 100, 'other': 28})\n",
      "#classes : 108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5583/1678916099.py:23: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'other' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df.loc[df[\"balanced_category\"] == category] = reject_class\n"
     ]
    }
   ],
   "source": [
    "threshold=100\n",
    "reject_class=\"other\"\n",
    "\n",
    "df[\"balanced_category\"] = df[\"primary_category\"]\n",
    "for category, count in primary_freq.items():\n",
    "    if count < threshold:\n",
    "        # retrieve the rare category and use the super_category label instead\n",
    "        super_category = df.loc[df[\"primary_category\"] == category, \"primary_category_super\"]\n",
    "        df.loc[df[\"primary_category\"] == category, \"balanced_category\"] = super_category\n",
    "\n",
    "title(\"BALANCED CATEG. FREQUENCY : FROM SMALL NODE TO PARENT NODE\")\n",
    "balanced_freq = Counter(df[\"balanced_category\"])\n",
    "print(balanced_freq)\n",
    "\n",
    "# WARNING: after this aggregation the following case may occur:\n",
    "# \"cond-mat.other\"  is below the threshold and other cond-mat.XXX classes are beyond the threshold. \n",
    "# It creates a situation where we are only renaming the class from \"cond-mat.other\" to \"cond-mat\".\n",
    "\n",
    "\n",
    "title(\"BALANCED CATEG. FREQUENCY 2 : FROM NODE TO REJECT NODE\")\n",
    "for category, count in balanced_freq.items():\n",
    "    if count < threshold:\n",
    "        df.loc[df[\"balanced_category\"] == category] = reject_class\n",
    "balanced_freq2 = Counter(df[\"balanced_category\"])\n",
    "print(balanced_freq2)\n",
    "print(\"#classes :\", len(balanced_freq2))\n",
    "# We have now the guarantee to have 0 or 1 class below the threshold named \"other\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6d19a-2a5f-4493-a3ad-773a3aa30b0b",
   "metadata": {},
   "source": [
    "# ML Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeb073fd-bca0-4aec-9be2-91b1253fde8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS=42 # random seed\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "# Suppress the sklearn FutureWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0459c60-3539-48a2-ab04-123739b6444a",
   "metadata": {},
   "source": [
    "## Evaluate different data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38264c6f-2ebd-4260-9431-4c4b50fe2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, top_k_accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import time\n",
    "\n",
    "def ml_exp(X,y,model):\n",
    "    # 3. Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=RS)\n",
    "    \n",
    "\n",
    "    # 5. Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Make predictions on the test set\n",
    "    start_time=time.time()\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_proba = model.predict_proba(X_test)  # Get probability scores\n",
    "    enlapsed_time=time.time()-start_time\n",
    "    \n",
    "    # 7. Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    top5_accuracy = top_k_accuracy_score(y_test, y_test_pred_proba, k=5)\n",
    "    f1 = f1_score(y_test, y_test_pred, average=\"weighted\")  # Weighted handles imbalance\n",
    "    result = {\"acc\": accuracy, \"top5\": top5_accuracy, \"f1\":f1, \"inftime\": enlapsed_time}\n",
    "    return result\n",
    "\n",
    "def display_exp(result:dict[str,float]):\n",
    "    accuracy=result[\"acc\"]\n",
    "    top5_accuracy=result[\"top5\"]\n",
    "    f1=result[\"f1\"]\n",
    "    enlapsed_time=result[\"inftime\"]\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Top-5 Accuracy: {top5_accuracy:.4f}\")\n",
    "    print(f\"  F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(f\"  Inference time (sec): {enlapsed_time:.4f}\")\n",
    "    \n",
    "\n",
    "# 4. TF-IDF Vectorization + Logistic Regression Pipeline\n",
    "def get_model():\n",
    "    model = make_pipeline(\n",
    "        TfidfVectorizer(stop_words='english', max_features=10000),  # TF-IDF vectorization with stop words removed\n",
    "        LogisticRegression(max_iter=1000, multi_class='ovr', random_state=RS, n_jobs=-1)  # Logistic Regression model\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13eccad1-a5b0-4cc6-87f7-81d470208656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m \u001b[1m *** DATA SOURCE: TITLE *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.5120\n",
      "  Top-5 Accuracy: 0.7783\n",
      "  F1-Score (Weighted): 0.4735\n",
      "  Inference time (sec): 0.2118\n",
      "\u001b[31m \u001b[1m *** DATA SOURCE: ABSTRACT *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6394\n",
      "  Top-5 Accuracy: 0.9072\n",
      "  F1-Score (Weighted): 0.6116\n",
      "  Inference time (sec): 0.7125\n",
      "\u001b[31m \u001b[1m *** DATA SOURCE: MARKDOWN *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6533\n",
      "  Top-5 Accuracy: 0.9146\n",
      "  F1-Score (Weighted): 0.6275\n",
      "  Inference time (sec): 5.8566\n",
      "\u001b[31m \u001b[1m *** DATA SOURCE: TITLE_PLUS_ABSTRACT *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6441\n",
      "  Top-5 Accuracy: 0.9138\n",
      "  F1-Score (Weighted): 0.6168\n",
      "  Inference time (sec): 0.7842\n",
      "\u001b[31m \u001b[1m *** DATA SOURCE: TITLE_PLUS_ABSTRACT_PLUS_INTRO *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6659\n",
      "  Top-5 Accuracy: 0.9211\n",
      "  F1-Score (Weighted): 0.6421\n",
      "  Inference time (sec): 6.2802\n"
     ]
    }
   ],
   "source": [
    "for data_source in [\"title\", \"abstract\", \"markdown\", \"title_plus_abstract\", \"title_plus_abstract_plus_intro\"]:\n",
    "    # Warning: slow with \"markdown\"\n",
    "    \n",
    "    X = df[data_source]  # features to predict balanced_category\n",
    "    y = df[\"balanced_category\"]  # Target variable\n",
    "\n",
    "    model = get_model()\n",
    "    exp_result = ml_exp(X,y, model)\n",
    "    title(f\"Data Source: {data_source}\")\n",
    "    display_exp(exp_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e10211-0635-435e-9ff4-1a6add92c785",
   "metadata": {},
   "source": [
    "## Evaluate cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816d9490-7648-4ec8-92c1-884b3f6da96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text from document:    Hello 4ll ! I am a self-instruct robot. ##### 404 \n",
      "Clean text `clean_english`: hello i am a self instruct robot\n",
      "Clean text `remove_stopwords`: Hello 4ll ! self-instruct robot. ##### 404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pierrick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))  # Set of English stopwords\n",
    "    words = text.split()  # Split the text into individual words\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]  # Remove stopwords\n",
    "    return ' '.join(filtered_words)  # Join the remaining words into a cleaned text\n",
    "\n",
    "raw_text = \"   Hello 4ll ! I am a self-instruct robot. ##### 404 \"\n",
    "print(\"Raw text from document:\", raw_text)\n",
    "print(\"Clean text `clean_english`:\", clean_english(raw_text))\n",
    "print(\"Clean text `remove_stopwords`:\", remove_stopwords(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afae3a1-5e94-4b46-b374-79c10ee80157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m \u001b[1m *** CLEANING STRATEGY: ABSTRACT *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6394\n",
      "  Top-5 Accuracy: 0.9072\n",
      "  F1-Score (Weighted): 0.6116\n",
      "  Inference time (sec): 0.8147\n",
      "\u001b[31m \u001b[1m *** CLEANING STRATEGY: CLEAN1 *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.5956\n",
      "  Top-5 Accuracy: 0.8832\n",
      "  F1-Score (Weighted): 0.5661\n",
      "  Inference time (sec): 0.5655\n",
      "\u001b[31m \u001b[1m *** CLEANING STRATEGY: CLEAN2 *** \u001b[0m \u001b[0m\n",
      "  Accuracy: 0.6402\n",
      "  Top-5 Accuracy: 0.9069\n",
      "  F1-Score (Weighted): 0.6128\n",
      "  Inference time (sec): 0.5980\n"
     ]
    }
   ],
   "source": [
    "data_source=\"abstract\"\n",
    "df[\"clean1\"] = df[data_source].apply(lambda v: clean_english(v))\n",
    "\n",
    "df[\"clean2\"] = df[data_source].apply(lambda v: remove_stopwords(v))\n",
    "\n",
    "for source_name in [data_source, \"clean1\", \"clean2\"]:\n",
    "    title(f\"CLEANING STRATEGY: {source_name}\")\n",
    "    X = df[source_name]  # features to predict balanced_category\n",
    "    y = df[\"balanced_category\"]  # Target variable\n",
    "    model = get_model()\n",
    "    res = ml_exp(X,y,model)\n",
    "    display_exp(res)\n",
    "\n",
    "# Conclusion: The cleaning functions are not used afterwards because it does not really improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e3110-17cd-4c3a-8829-139d26578bd1",
   "metadata": {},
   "source": [
    "## Evaluate summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c634cd6d-b264-49ff-a776-64292bbb0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Your max_length is set to 100, but your input_length is only 82. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: the quick brown fox jumped over the lazy dog! but wait!! There's more: the fox didn't stop at the dog . bla bla is a self-instructing robot. it's not a robot .  #words in: 232  #words out: 159\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# I put on the CPU for avoiding tone of cuda warnings and it seems not slower\n",
    "summarizer_model=\"t5-small\"\n",
    "#summarizer_model=\"facebook/bart-large-cnn\" # good but slow\n",
    "summarizer = pipeline(\"summarization\", model=summarizer_model, device=-1) \n",
    "\n",
    "text = \"\"\"\n",
    "Hello 4ll ! I am a self-instruct robot. ##### 404  . I will tell you a story about a fox I have heard once.\n",
    "The quick brown fox jumped over the lazy dog! But wait!! There's more: the fox didn't stop at the dog. The fox... bla bla.\n",
    "\"\"\"\n",
    "\n",
    "def summary_and_clean(text):\n",
    "    max_length=100 # max #words\n",
    "    min_length=50\n",
    "    chucnk_size=512\n",
    "    if len(text.split()) > chucnk_size:  # If it's too long, split into chunks\n",
    "        chunks = [text[i:i + chucnk_size] for i in range(0, len(text), chucnk_size)]\n",
    "        summaries = []\n",
    "        for chunk in chunks:\n",
    "            summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "            summaries.append(summary[0]['summary_text'])\n",
    "        return ' '.join(summaries)  # Join all chunk summaries\n",
    "    else:\n",
    "        # Otherwise summarize normally\n",
    "        summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "    return out\n",
    "\n",
    "summarized=summary_and_clean(text)\n",
    "print(\"Summary:\", summarized, \" #words in:\", len(text), \" #words out:\", len(summarized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cfc91d-028d-43fc-9aa6-3f1dfbe159d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training ...\n",
      "summarization ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but your input_length is only 68. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n",
      "Your max_length is set to 100, but your input_length is only 82. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test markdown vs summarized_markdown\n",
      "num_correct_markdown:  1\n",
      "num_correct_summarized:  2\n"
     ]
    }
   ],
   "source": [
    "data_source = \"abstract\"\n",
    "\n",
    "print(\"model training ...\")\n",
    "N = 3 # <--- It takes several minutes with N=3 !!! \n",
    "X = df[\"abstract\"][N:]\n",
    "y = df[\"balanced_category\"][N:]\n",
    "model = get_model()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"summarization ...\") # /!\\ SLOW !!!\n",
    "X2 = []\n",
    "for i in range(N):\n",
    "    markdown = df[\"markdown\"][i]\n",
    "    summarized_markdown = summary_and_clean(markdown)\n",
    "    X2.append(summarized_markdown)\n",
    "\n",
    "\n",
    "print(\"test markdown vs summarized_markdown\")\n",
    "num_correct_markdown = 0\n",
    "num_correct_summarized = 0\n",
    "for i in range(N):\n",
    "    correct_class = df[\"balanced_category\"][i]\n",
    "    markdown = df[\"markdown\"][i]\n",
    "    markdown_summarized = X2[i]\n",
    "    \n",
    "    # Predict with the original markdown\n",
    "    out1 = model.predict([markdown])[0]\n",
    "    \n",
    "    # Predict with the summarized markdown\n",
    "    out2 = model.predict([markdown_summarized])[0]\n",
    "    \n",
    "    # Check if predictions match the correct class\n",
    "    if out1 == correct_class:\n",
    "        num_correct_markdown += 1\n",
    "    if out2 == correct_class:\n",
    "        num_correct_summarized += 1\n",
    "\n",
    "print(\"num_correct_markdown: \", num_correct_markdown)\n",
    "print(\"num_correct_summarized: \", num_correct_summarized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbffa9f-938e-44d1-bbcc-f1ae6ee0384a",
   "metadata": {},
   "source": [
    "## Evaluate different ML algo (default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc54135-2b42-42a2-9385-474b3ec4d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression...\n",
      "  Accuracy: 0.6394\n",
      "  Top-5 Accuracy: 0.9072\n",
      "  F1-Score (Weighted): 0.6116\n",
      "  Inference time (sec): 1.1218\n",
      "Evaluating RandomForest...\n",
      "  Accuracy: 0.4998\n",
      "  Top-5 Accuracy: 0.7792\n",
      "  F1-Score (Weighted): 0.4284\n",
      "  Inference time (sec): 1.3379\n",
      "Evaluating MLP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.6667\n",
      "  Top-5 Accuracy: 0.9339\n",
      "  F1-Score (Weighted): 0.6594\n",
      "  Inference time (sec): 0.8981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "\n",
    "X = df[\"abstract\"] # <--- abstract is enough for quick experimentations\n",
    "y = df[\"balanced_category\"]\n",
    "\n",
    "# 4. Model Definitions\n",
    "tfidf=TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "models = {\n",
    "    \"LogisticRegression\": make_pipeline(tfidf, LogisticRegression(max_iter=1000, multi_class='ovr', random_state=RS, n_jobs=-1)),\n",
    "    \"RandomForest\": make_pipeline(tfidf, RandomForestClassifier(max_depth=50,random_state=RS, n_jobs=-1)),\n",
    "    \"MLP\": make_pipeline(tfidf, MLPClassifier(max_iter=10, random_state=RS))\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    res = ml_exp(X,y, model)\n",
    "    display_exp(res)\n",
    "\n",
    "# Conclusion MLP: good ratio accuracy vs time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980516d-326a-4907-85a6-4e967f26bd56",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "904fff1f-0ed5-4b57-8168-ac66c8b7a46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'mlpclassifier__learning_rate_init': 0.01, 'mlpclassifier__learning_rate': 'constant', 'mlpclassifier__hidden_layer_sizes': (400,), 'mlpclassifier__alpha': 0.0}\n",
      "Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(max_features=10000, stop_words='english')),\n",
      "                ('mlpclassifier',\n",
      "                 MLPClassifier(alpha=0.0, hidden_layer_sizes=(400,),\n",
      "                               learning_rate_init=0.01, max_iter=1,\n",
      "                               random_state=42))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your dataframe and the target column is 'balanced_category'\n",
    "X = df[\"abstract\"]\n",
    "y = df[\"balanced_category\"]\n",
    "\n",
    "# MLP Model Pipeline\n",
    "mlp_model = make_pipeline(TfidfVectorizer(stop_words='english', max_features=10000), \n",
    "                          MLPClassifier(max_iter=1, random_state=42))\n",
    "\n",
    "# Define the hyperparameter distributions to sample from\n",
    "param_dist = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(100,), (200,), (400,), (100, 100)],\n",
    "    'mlpclassifier__alpha': [0., 0.0001, 0.001, 0.01, 0.1],\n",
    "    'mlpclassifier__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'mlpclassifier__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV to sample 200 combinations\n",
    "random_search = RandomizedSearchCV(estimator=mlp_model, param_distributions=param_dist, \n",
    "                                   n_iter=10, cv=2, n_jobs=-1, verbose=1, random_state=42)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best parameters found by RandomizedSearchCV\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "best_model = random_search.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868b49f-5b87-4399-b039-913d38ff15bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b716bd-7acf-4844-a68f-12454c71f804",
   "metadata": {},
   "source": [
    "## FINAL TRAINING!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f1d177-87cd-4067-8f68-5a15ddac53b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.6769\n",
      "  Top-5 Accuracy: 0.9315\n",
      "  F1-Score (Weighted): 0.6679\n",
      "  Inference time (sec): 5.8001\n"
     ]
    }
   ],
   "source": [
    "# Get the best estimator\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.named_steps['mlpclassifier'].max_iter = 1 # <--- does not improve\n",
    "X = df[\"markdown\"]\n",
    "y = df[\"balanced_category\"]\n",
    "res = ml_exp(X,y, best_model)\n",
    "display_exp(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8ccd2-1f00-4818-894f-42d346963b9e",
   "metadata": {},
   "source": [
    "# Model saving / restoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305ffb9-31c2-4ba3-814b-e700ad197253",
   "metadata": {},
   "source": [
    "## Saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39e51723-a262-49bf-9c36-5313ac6c97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (Pickle)\n",
    "import pickle\n",
    "with open(f\"{MODEL_PATH}/model.pkl\", 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save the class names\n",
    "class_names = y.unique()  # Get the class names\n",
    "with open(f\"/{MODEL_PATH}/class_names.pkl\", 'wb') as f:\n",
    "    pickle.dump(class_names, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a75247b-2888-48f4-8a9f-0e48bfdca861",
   "metadata": {},
   "source": [
    "## Restoring it (code to use in gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec193189-4092-42ab-8f1d-07cfd687797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/{MODEL_PATH}/model.pkl\", 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "with open(f\"/{MODEL_PATH}/class_names.pkl\", 'rb') as f:\n",
    "    class_names = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8a9ab-5174-4969-b79f-58f6ceb10d9b",
   "metadata": {},
   "source": [
    "## Using it (code to use in gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a3cd098-4089-40e9-b2e2-aa1b583f5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comet 162P/Siding Spring is a large Jupiter-family comet with extensive\n",
      "archival lightcurve data. We report new r-band nucleus lightcurves for this\n",
      "comet, acquired in 2018, 2021 and 2022. With the addition of these lightcurves,\n",
      "the phase angles at which the nucleus has been observed range from $0.39^\\circ$\n",
      "to $16.33^\\circ$. We absolutely-calibrate the comet lightcurves to r-band\n",
      "Pan-STARRS 1 magnitudes, and use these lightcurves to create a convex shape\n",
      "model of the nucleus by convex lightcurve inversion. The best-fitting shape\n",
      "model for 162P has axis ratios $a/b = 1.56$ and $b/c = 2.33$, sidereal period\n",
      "$P = 32.864\\pm0.001$ h, and a rotation pole oriented towards ecliptic longitude\n",
      "$\\lambda_E = 118^\\circ \\pm 26^\\circ$ and latitude\n",
      "$\\beta_E=-50^\\circ\\pm21^\\circ$. We constrain the possible nucleus elongation to\n",
      "lie within $1.4 < a/b < 2.0$ and discuss tentative evidence that 162P may have\n",
      "a bilobed structure. Using the shape model to correct the lightcurves for\n",
      "rotational effects, we derive a linear phase function with slope\n",
      "$\\beta=0.051\\pm0.002$ mag deg$^{-1}$ and intercept $H_r(1,1,0) = 13.86 \\pm\n",
      "0.02$ for 162P. We find no evidence that the nucleus exhibited an opposition\n",
      "surge at phase angles down to 0.39$^\\circ$. The challenges associated with\n",
      "modelling the shapes of comet nuclei from lightcurves are highlighted, and we\n",
      "comment on the extent to which we anticipate that LSST will alleviate these\n",
      "challenges in the coming decade.\n",
      "Expected class: astro-ph.EP\n"
     ]
    }
   ],
   "source": [
    "# Take some data\n",
    "text=df[\"abstract\"][0]\n",
    "label=df[\"balanced_category\"][0]\n",
    "print(text)\n",
    "print(\"Expected class:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c780136-7d55-49b8-aaa7-6c806a042bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physics.plasm-ph: 93.20%\n",
      "cond-mat.supr-con: 1.10%\n",
      "cs.SI: 0.54%\n",
      "math.AP: 0.48%\n",
      "cs.CY: 0.46%\n"
     ]
    }
   ],
   "source": [
    "predicted_probs = loaded_model.predict_proba([text])\n",
    "top_5_indices = predicted_probs.argsort()[0][-5:][::-1]  # Get the indices of top 5 predictions\n",
    "\n",
    "top_5_classes = class_names[top_5_indices]  # Get the corresponding class names\n",
    "top_5_probs = predicted_probs[0][top_5_indices]  # Get the corresponding probabilities\n",
    "\n",
    "# Print the top 5 predicted classes and their probabilities\n",
    "strings_out=[]\n",
    "for cls, prob in zip(top_5_classes, top_5_probs):\n",
    "    strings_out.append(f\"{cls}: {prob*100:.2f}%\")\n",
    "out=\"\\n\".join(strings_out)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2202cce-27af-432b-953f-f3f34225bde6",
   "metadata": {},
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b487851-9c4e-4ce9-8377-44bde0138b49",
   "metadata": {},
   "source": [
    "## Training preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2130d5cb-5880-4799-9712-2eb3b2b03d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA RTX A1000 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # Should be True\n",
    "print(torch.cuda.device_count())  # Should be > 0\n",
    "print(torch.cuda.get_device_name(0))  # Should print GPU name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03dc6b2f-db29-434e-a2d1-a80f064d2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load  # Correct way to load metrics in Hugging Face\n",
    "import numpy as np\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "# Load evaluation metrics\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)  # Get top-1 prediction\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # Compute F1-score (for classification)\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
    "\n",
    "    # Compute Top-5 accuracy (for multi-class classification)\n",
    "    top5_acc = top_k_accuracy_score(labels, logits, k=5, labels=np.arange(logits.shape[1]))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "        \"top5_accuracy\": top5_acc,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82b0f294-4406-43b7-a1a3-d4154edb7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {0: np.str_('astro-ph.CO'), 1: np.str_('astro-ph.EP'), 2: np.str_('astro-ph.GA'), 3: np.str_('astro-ph.HE'), 4: np.str_('astro-ph.IM'), 5: np.str_('astro-ph.SR'), 6: np.str_('cond-mat.dis-nn'), 7: np.str_('cond-mat.mes-hall'), 8: np.str_('cond-mat.mtrl-sci'), 9: np.str_('cond-mat.quant-gas'), 10: np.str_('cond-mat.soft'), 11: np.str_('cond-mat.stat-mech'), 12: np.str_('cond-mat.str-el'), 13: np.str_('cond-mat.supr-con'), 14: np.str_('cs'), 15: np.str_('cs.AI'), 16: np.str_('cs.AR'), 17: np.str_('cs.CC'), 18: np.str_('cs.CE'), 19: np.str_('cs.CL'), 20: np.str_('cs.CR'), 21: np.str_('cs.CV'), 22: np.str_('cs.CY'), 23: np.str_('cs.DB'), 24: np.str_('cs.DC'), 25: np.str_('cs.DL'), 26: np.str_('cs.DS'), 27: np.str_('cs.FL'), 28: np.str_('cs.GR'), 29: np.str_('cs.GT'), 30: np.str_('cs.HC'), 31: np.str_('cs.IR'), 32: np.str_('cs.IT'), 33: np.str_('cs.LG'), 34: np.str_('cs.LO'), 35: np.str_('cs.MA'), 36: np.str_('cs.NE'), 37: np.str_('cs.NI'), 38: np.str_('cs.PL'), 39: np.str_('cs.RO'), 40: np.str_('cs.SD'), 41: np.str_('cs.SE'), 42: np.str_('cs.SI'), 43: np.str_('econ'), 44: np.str_('econ.GN'), 45: np.str_('eess.AS'), 46: np.str_('eess.IV'), 47: np.str_('eess.SP'), 48: np.str_('eess.SY'), 49: np.str_('gr-qc'), 50: np.str_('hep-ex'), 51: np.str_('hep-lat'), 52: np.str_('hep-ph'), 53: np.str_('hep-th'), 54: np.str_('math'), 55: np.str_('math-ph'), 56: np.str_('math.AC'), 57: np.str_('math.AG'), 58: np.str_('math.AP'), 59: np.str_('math.AT'), 60: np.str_('math.CA'), 61: np.str_('math.CO'), 62: np.str_('math.CT'), 63: np.str_('math.CV'), 64: np.str_('math.DG'), 65: np.str_('math.DS'), 66: np.str_('math.FA'), 67: np.str_('math.GM'), 68: np.str_('math.GR'), 69: np.str_('math.GT'), 70: np.str_('math.LO'), 71: np.str_('math.NA'), 72: np.str_('math.NT'), 73: np.str_('math.OA'), 74: np.str_('math.OC'), 75: np.str_('math.PR'), 76: np.str_('math.RA'), 77: np.str_('math.RT'), 78: np.str_('math.ST'), 79: np.str_('nlin'), 80: np.str_('nucl-ex'), 81: np.str_('nucl-th'), 82: np.str_('other'), 83: np.str_('physics'), 84: np.str_('physics.acc-ph'), 85: np.str_('physics.ao-ph'), 86: np.str_('physics.app-ph'), 87: np.str_('physics.atom-ph'), 88: np.str_('physics.bio-ph'), 89: np.str_('physics.chem-ph'), 90: np.str_('physics.comp-ph'), 91: np.str_('physics.flu-dyn'), 92: np.str_('physics.geo-ph'), 93: np.str_('physics.ins-det'), 94: np.str_('physics.med-ph'), 95: np.str_('physics.optics'), 96: np.str_('physics.plasm-ph'), 97: np.str_('physics.soc-ph'), 98: np.str_('q-bio'), 99: np.str_('q-bio.NC'), 100: np.str_('q-bio.PE'), 101: np.str_('q-bio.QM'), 102: np.str_('q-fin'), 103: np.str_('quant-ph'), 104: np.str_('stat'), 105: np.str_('stat.AP'), 106: np.str_('stat.ME'), 107: np.str_('stat.ML')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████| 63357/63357 [00:12<00:00, 5141.35 examples/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/pierrick/project/ARXIV/python/myenv/lib/python3.13/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# ===========================\n",
    "# LOAD DATASET\n",
    "# ===========================\n",
    "X = df[\"abstract\"].tolist()\n",
    "y = df[\"balanced_category\"].tolist()\n",
    "batch_size=64\n",
    "\n",
    "# ===========================\n",
    "# CONVERT LABELS TO NUMBERS\n",
    "# ===========================\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # Convert text labels to integers\n",
    "num_labels = len(label_encoder.classes_)  # Number of unique classes\n",
    "\n",
    "# Save mapping (optional)\n",
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "# ===========================\n",
    "# TOKENIZATION (USING BERT TOKENIZER)\n",
    "# ===========================\n",
    "#MODEL_NAME = \"bert-base-uncased\"  # Pretrained BERT model . Too large\n",
    "MODEL_NAME = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Convert text into tokenized format\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "# Convert dataset into Hugging Face Dataset format\n",
    "df_hf = pd.DataFrame({\"text\": X, \"label\": y_encoded})\n",
    "dataset = Dataset.from_pandas(df_hf)\n",
    "\n",
    "# Apply tokenization\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# ===========================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ===========================\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# ===========================\n",
    "# LOAD BERT CLASSIFIER\n",
    "# ===========================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "# ===========================\n",
    "# TRAINING PARAMETERS (Optimized for CPU)\n",
    "# ===========================\n",
    "training_args = TrainingArguments(\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5, # <--- tune it. 10 -> 20 minutes\n",
    "    logging_dir=f\"/{MODEL_PATH}/pytorch_logs\",\n",
    "    output_dir=f\"/{MODEL_PATH}/pytorch_checkpoint\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=0.001,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics # custom metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92c429-cd8f-42b7-a839-0dcfd9872430",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Takes ~20 minutes on with my Nvidia A1000 6G GPU Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8226ebf-dd24-4dfb-84b3-b4d936ce395d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4455' max='4455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4455/4455 11:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Top5 Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.839600</td>\n",
       "      <td>1.680987</td>\n",
       "      <td>0.540720</td>\n",
       "      <td>0.488678</td>\n",
       "      <td>0.846275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.373400</td>\n",
       "      <td>1.467601</td>\n",
       "      <td>0.593434</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>0.875631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.980400</td>\n",
       "      <td>1.421646</td>\n",
       "      <td>0.610322</td>\n",
       "      <td>0.593514</td>\n",
       "      <td>0.882734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>1.457634</td>\n",
       "      <td>0.611427</td>\n",
       "      <td>0.600043</td>\n",
       "      <td>0.882891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.569900</td>\n",
       "      <td>1.515708</td>\n",
       "      <td>0.612847</td>\n",
       "      <td>0.603271</td>\n",
       "      <td>0.881155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [99/99 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 1.4216464757919312, 'eval_accuracy': 0.6103219696969697, 'eval_f1': 0.5935139287044443, 'eval_top5_accuracy': 0.8827335858585859, 'eval_runtime': 6.5289, 'eval_samples_per_second': 970.448, 'eval_steps_per_second': 15.163, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e67ed34-3bec-43d9-ae46-b87c73e25899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the trained model\n",
    "model.save_pretrained(f\"/{MODEL_PATH}/saved_model\")\n",
    "tokenizer.save_pretrained(f\"/{MODEL_PATH}/saved_model\")\n",
    "with open(f\"/{MODEL_PATH}/label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998fb9c9-a6e8-4809-9c95-a1d5e7dec171",
   "metadata": {},
   "source": [
    "## Inference mode (CODE TO PUT IN GRADIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f24b5aab-4aab-43e1-b393-0a853140115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"/{MODEL_PATH}/saved_model\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"/{MODEL_PATH}/saved_model\")\n",
    "with open(f\"/{MODEL_PATH}/label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "\n",
    "# Inference function\n",
    "def predict_text(text):\n",
    "    tokens = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    logits = output.logits\n",
    "    top5_probs, top5_indices = torch.topk(logits, k=5, dim=1)  # Get top 5 classes\n",
    "    top5_labels = label_encoder.inverse_transform(top5_indices.cpu().numpy().flatten())\n",
    "    top5_probs = torch.nn.functional.softmax(top5_probs, dim=1).cpu().numpy().flatten()\n",
    "    res = [(label, float(prob)) for label, prob in zip(top5_labels, top5_probs)]\n",
    "    res = sorted(res, reverse=True, key=lambda p:p[1])\n",
    "\n",
    "    lines=[]\n",
    "    for pair in res:\n",
    "        label=f\"{pair[0]}: {pair[1]*100:.2f}%\"\n",
    "        lines.append(label)\n",
    "    out=\"\\n\".join(lines)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee73e2f-348b-43d4-835f-cd8be1f68a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comet 162P/Siding Spring is a large Jupiter-family comet with extensive\n",
      "archival lightcurve data. We report new r-band nucleus lightcurves for this\n",
      "comet, acquired in 2018, 2021 and 2022. With the addition of these lightcurves,\n",
      "the phase angles at which the nucleus has been observed range from $0.39^\\circ$\n",
      "to $16.33^\\circ$. We absolutely-calibrate the comet lightcurves to r-band\n",
      "Pan-STARRS 1 magnitudes, and use these lightcurves to create a convex shape\n",
      "model of the nucleus by convex lightcurve inversion. The best-fitting shape\n",
      "model for 162P has axis ratios $a/b = 1.56$ and $b/c = 2.33$, sidereal period\n",
      "$P = 32.864\\pm0.001$ h, and a rotation pole oriented towards ecliptic longitude\n",
      "$\\lambda_E = 118^\\circ \\pm 26^\\circ$ and latitude\n",
      "$\\beta_E=-50^\\circ\\pm21^\\circ$. We constrain the possible nucleus elongation to\n",
      "lie within $1.4 < a/b < 2.0$ and discuss tentative evidence that 162P may have\n",
      "a bilobed structure. Using the shape model to correct the lightcurves for\n",
      "rotational effects, we derive a linear phase function with slope\n",
      "$\\beta=0.051\\pm0.002$ mag deg$^{-1}$ and intercept $H_r(1,1,0) = 13.86 \\pm\n",
      "0.02$ for 162P. We find no evidence that the nucleus exhibited an opposition\n",
      "surge at phase angles down to 0.39$^\\circ$. The challenges associated with\n",
      "modelling the shapes of comet nuclei from lightcurves are highlighted, and we\n",
      "comment on the extent to which we anticipate that LSST will alleviate these\n",
      "challenges in the coming decade.\n",
      "Expected class: astro-ph.EP\n",
      "Predicted Category: astro-ph.EP: 95.29%\n",
      "astro-ph.SR: 1.75%\n",
      "astro-ph.IM: 1.54%\n",
      "physics.geo-ph: 1.16%\n",
      "physics.ao-ph: 0.26%\n"
     ]
    }
   ],
   "source": [
    "# Take some data\n",
    "text=df[\"abstract\"][0]\n",
    "label=df[\"balanced_category\"][0]\n",
    "print(text)\n",
    "print(\"Expected class:\", label)\n",
    "\n",
    "# Example Prediction\n",
    "predicted_category = predict_text(text)\n",
    "print(\"Predicted Category:\", predicted_category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed74e5e-b05d-4a77-a940-73af93c8d876",
   "metadata": {},
   "source": [
    "# LLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17171d3f-3f6f-4820-88ee-89fddd73cd4a",
   "metadata": {},
   "source": [
    "## Load model for pre-processing / post-processing (code to put in gradio directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dfe8b69-81d6-4c56-997b-71a4a456f6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astro-ph.EP' 'physics.plasm-ph' 'math.RA' 'cs.CL' 'math.AP' 'eess.SY'\n",
      " 'stat.ME' 'math.FA' 'physics.optics' 'eess.IV' 'cs.AI' 'hep-th' 'cs.CV'\n",
      " 'nucl-th' 'cs' 'astro-ph.HE' 'cs.RO' 'cs.LG' 'astro-ph.SR' 'cs.CY'\n",
      " 'cs.LO' 'astro-ph.GA' 'physics.app-ph' 'cs.IT' 'cs.SE' 'physics.bio-ph'\n",
      " 'physics' 'cond-mat.mtrl-sci' 'quant-ph' 'econ.GN' 'physics.acc-ph'\n",
      " 'math.PR' 'math.AG' 'cond-mat.str-el' 'hep-ph' 'cond-mat.soft' 'gr-qc'\n",
      " 'q-bio.QM' 'math.OC' 'physics.flu-dyn' 'math.DG' 'cs.HC' 'cs.PL' 'cs.DB'\n",
      " 'cs.CE' 'cs.NI' 'math.NA' 'cs.GT' 'cs.GR' 'math.AT' 'cs.DC' 'hep-ex'\n",
      " 'math.NT' 'cs.DL' 'astro-ph.CO' 'eess.AS' 'cond-mat.quant-gas'\n",
      " 'cond-mat.mes-hall' 'physics.chem-ph' 'q-bio.NC' 'cs.CR' 'math-ph'\n",
      " 'stat.ML' 'math.GR' 'physics.ao-ph' 'nucl-ex' 'math' 'math.GM' 'q-fin'\n",
      " 'astro-ph.IM' 'eess.SP' 'math.ST' 'nlin' 'physics.atom-ph' 'cs.DS'\n",
      " 'cs.SD' 'math.DS' 'math.RT' 'cond-mat.stat-mech' 'stat' 'cs.CC'\n",
      " 'physics.geo-ph' 'math.CO' 'cs.IR' 'math.LO' 'cond-mat.supr-con'\n",
      " 'math.GT' 'math.CV' 'q-bio.PE' 'physics.soc-ph' 'cs.NE' 'math.CT' 'cs.SI'\n",
      " 'physics.ins-det' 'q-bio' 'math.OA' 'cs.FL' 'math.CA' 'math.AC'\n",
      " 'cond-mat.dis-nn' 'cs.MA' 'hep-lat' 'physics.med-ph' 'stat.AP' 'other'\n",
      " 'physics.comp-ph' 'cs.AR' 'econ']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "\n",
    "with open(f\"/tmp/class_names.pkl\", 'rb') as f:\n",
    "    class_names = pickle.load(f)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182a6bf-30ec-4d7a-ac93-d1cf6ac8f92a",
   "metadata": {},
   "source": [
    "## Inference (code to put in gradio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a2823be-30cf-4cf5-9a26-8189d14d0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inference(sample_text):\n",
    "\n",
    "    # OpenRouter API Endpoint\n",
    "    API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    \n",
    "    # Choose a free model (Mistral is free)\n",
    "    MODEL_NAME = \"mistralai/mistral-7b-instruct\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Define Prompt for ArXiv Category Classification\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in scientific paper classification. Given the abstract below, classify it into one of the official arXiv categories. \n",
    "    \n",
    "    Below the paper:\n",
    "    {sample_text}\n",
    "    \n",
    "    Return only a category code among: {class_names}.\n",
    "    Your answer should be only 20 characters maximum.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare API Request\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {OPENAI_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.1,  # Lower temperature for more deterministic responses\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    "    \n",
    "    # Send Request\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    \n",
    "    # Exctract the response\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        llm_output = result[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        class_name=\"other\"\n",
    "        for class_name in class_names:\n",
    "            if class_name in llm_output:\n",
    "                break\n",
    "        out = class_name\n",
    "    else:\n",
    "        out = response.text\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a243a-6638-4b30-b9f0-af1dae125780",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "/!\\ WARNING: Call it only once !!!!\n",
    "\n",
    "Don't spam too much my OpenAI account please :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96bfb501-1d9c-4664-9239-7674b22ad7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_good_answer=0\n",
    "num_questions=10 \n",
    "\n",
    "start_time=time.time()\n",
    "for i in range(num_questions):\n",
    "    text=df[\"abstract\"][i]\n",
    "    label=df[\"balanced_category\"][i]\n",
    "    pred = inference(text)\n",
    "    if label==pred:\n",
    "        num_good_answer+=1\n",
    "\n",
    "enlapsed_time=time.time()-start_time\n",
    "enlapsed_time_if_tested_like_other_models = (enlapsed_time/num_questions)*(0.1*len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f39ec42-ace5-42f0-8921-3285ea6a926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated accuracy:  0.7\n",
      "Estimated inference time for test set: 6709.236008477212\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated accuracy: \", float(num_good_answer)/num_questions)\n",
    "print(\"Estimated inference time for test set:\", enlapsed_time_if_tested_like_other_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79094c5-3cec-4652-aafc-2a8d47f8243f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
